{"hugging_face_token": "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", "groq_api_key": "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", "framework": "rag", "project": "rag", "test_dataset": "/Users/hadiibrahim/Dev/prima-power-hmi-assistant/src/data/final_selection.csv", "train_dataset": "/Users/hadiibrahim/Dev/prima-power-hmi-assistant/src/data/trainset_manual.csv", "exp_name": "rag_exp_llm_k_rag_7", "phase": "all", "not_use_local_logging": false, "not_use_wandb": false, "seed": 516, "epoch": 20, "train_batch_size": 20, "val_batch_size": 4, "test_batch_size": 1, "model_name": "llama-3.1-70b-Versatile", "temperature": 0.0, "k_few_shot": 2, "k_rag": 7, "is_llm": false, "answers_folder": null, "load_checkpoint": false, "model_checkpoint": "./new_weights_comet/final_Trial1_context_comet", "test_output_file_name": "results.json", "docs": "/Users/hadiibrahim/Dev/prima-power-hmi-assistant/src/docs.pkl", "vector_store_type": "FAISS", "embedding_model": "hf_embeddings", "reranking": false, "refine_query": false, "method": "llm_chain_extractor"}