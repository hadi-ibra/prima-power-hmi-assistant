{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma, FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "from langchain_community.llms import HuggingFaceHub\n",
    "from langchain_groq import ChatGroq\n",
    "import pickle\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "os.environ['HUGGINGFACEHUB_API_TOKEN']=os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")\n",
    "groq_api_key = os.environ[\"GROQ_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hadiibrahim/anaconda3/envs/temp-env/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `HuggingFaceHub` was deprecated in LangChain 0.0.21 and will be removed in 0.3.0. Use HuggingFaceEndpoint instead.\n",
      "  warn_deprecated(\n",
      "/Users/hadiibrahim/anaconda3/envs/temp-env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "hf=HuggingFaceHub(\n",
    "    repo_id=\"meta-llama/Meta-Llama-3-70B\",\n",
    "    model_kwargs={\"temperature\":0.1}\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(groq_api_key=groq_api_key,model_name=\"llama3-70b-8192\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "query = \"What are the advantages of a 3D printer?\"\n",
    "\n",
    "prompt = f\"Refine the following query for better retrieval. Only return the refined query, without any additional text or explanation:\\n\\n{query}\"\n",
    "\n",
    "# Get the refined query from the LLM\n",
    "response = llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What are the benefits and advantages of using 3D printing technology?'"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_file = \"/Users/hadiibrahim/Dev/prima-power-hmi-assistant/data/chunks.pkl\"\n",
    "with open(pickle_file, \"rb\") as file:\n",
    "    docs_manual = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_file = \"/Users/hadiibrahim/Dev/prima-power-hmi-assistant/data/alarm_info_list.pkl\"\n",
    "with open(pickle_file, \"rb\") as file:\n",
    "    docs_alarm = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_list = docs_manual + docs_alarm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3315"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.docstore.document import Document\n",
    "\n",
    "documents_manual = [\n",
    "    Document(page_content=text, metadata={\"source\": \"TULUS manual software\"})\n",
    "    for text in docs_manual\n",
    "]\n",
    "\n",
    "documents_alarm = [\n",
    "    Document(page_content=text, metadata={\"source\": \"TULUS - Alarms\"})\n",
    "    for text in docs_alarm\n",
    "]\n",
    "\n",
    "docs = documents_manual + documents_alarm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_pickle_file = \"docs.pkl\"\n",
    "with open(output_pickle_file, 'wb') as f:\n",
    "    # Dump the concatenated list into the pickle file\n",
    "    pickle.dump(docs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the embeddings and vector store\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "\n",
    "vector_store_chroma = Chroma.from_documents(docs,embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store_faiss = FAISS.from_documents(docs,embeddings)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a prompt template for the language model\n",
    "prompt_template = PromptTemplate(input_variables=[\"context\", \"question\"],\n",
    "                                 template=\"Given the following context: {context}, answer the question: {question}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever=vector_store_chroma.as_retriever(search_type=\"similarity\",search_kwargs={\"k\":4})\n",
    "# retriever=vector_store_chroma.as_retriever(search_type=\"similarity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "retrievalQA=RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\":prompt_template}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: There are 4 Alarm IDs mentioned in the provided context:\n",
      "\n",
      "1. Alarm ID: 32/147\n",
      "2. Alarm ID: 352\n",
      "3. Alarm ID: 22/44\n",
      "4. Alarm ID: 0/1282\n",
      "Chunks Used:\n",
      "Document : 0\n",
      "Metadata: {'source': 'TULUS - Alarms'}\n",
      "\n",
      "Document : 1\n",
      "Metadata: {'source': 'TULUS - Alarms'}\n",
      "\n",
      "Document : 2\n",
      "Metadata: {'source': 'TULUS - Alarms'}\n",
      "\n",
      "Document : 3\n",
      "Metadata: {'source': 'TULUS - Alarms'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Function to retrieve answer and chunks used\n",
    "def get_answer_and_chunks(query):\n",
    "    # Use the qa_chain to get the answer and source documents\n",
    "    \n",
    "    result = retrievalQA.invoke({\"query\": query})\n",
    "    \n",
    "    # Extract the answer and source documents\n",
    "    answer = result[\"result\"]\n",
    "    source_documents = result[\"source_documents\"]\n",
    "    \n",
    "    return answer, source_documents\n",
    "\n",
    "# Define a query and retrieve the answer along with chunks\n",
    "query = \"how many alari Ids are there in tulus\"\n",
    "answer, source_docs = get_answer_and_chunks(query)\n",
    "\n",
    "print(\"Answer:\", answer)\n",
    "print(\"Chunks Used:\")\n",
    "\n",
    "\n",
    "if source_docs:\n",
    "    for index,chunk in enumerate(source_docs):\n",
    "        print(\"Document :\", index)\n",
    "        # print(chunk.page_content)\n",
    "        print(\"Metadata:\", chunk.metadata)\n",
    "        print()\n",
    "else:\n",
    "    print(\"No chunks used\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## replace index in original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "file_path='/Users/hadiibrahim/Dev/prima-power-hmi-assistant/src/data/main_manual_file_with_index (1).csv'\n",
    "df=pd.read_csv(file_path,sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_file = \"/Users/hadiibrahim/Dev/prima-power-hmi-assistant/data/chunks.pkl\"\n",
    "with open(pickle_file, \"rb\") as file:\n",
    "    chunks = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_context(df, new_context_list):\n",
    "    # Replace each context value based on the context_index\n",
    "    df['context'] = df['closest_text_index'].apply(lambda x: new_context_list[x])\n",
    "    return df\n",
    "\n",
    "# Apply the function\n",
    "df = replace_context(df, chunks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main= df.drop(columns=[\"correct_answers\",\"incorrect_answers\",\"closest_text_index\",\"category\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main.rename(columns={\"best_answer\":\"answer\"},inplace=True)\n",
    "df_main.rename(columns={\"context\":\"contexts\"},inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contexts</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n2. TULUS  user interface\\n2.1 Introduction\\n...</td>\n",
       "      <td>What is the main purpose of the Tulus software?</td>\n",
       "      <td>The main purpose of the Tulus software is to m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n2. TULUS  user interface\\n2.1 Introduction\\n...</td>\n",
       "      <td>What are some key components of the Tulus user...</td>\n",
       "      <td>Some key components of the Tulus user interfac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n2. TULUS  user interface\\n2.1 Introduction\\n...</td>\n",
       "      <td>What functions are available on the vertical t...</td>\n",
       "      <td>The vertical toolbar in the Tulus interface in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\n2. TULUS  user interface\\n2.1 Introduction\\n...</td>\n",
       "      <td>What information is displayed in the notificat...</td>\n",
       "      <td>The notification area displays messages about ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\n2. TULUS  user interface\\n2.1 Introduction\\n...</td>\n",
       "      <td>What kind of controls and information can be f...</td>\n",
       "      <td>The \"Customer\" section of the Tulus interface ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            contexts  \\\n",
       "0  \\n2. TULUS  user interface\\n2.1 Introduction\\n...   \n",
       "1  \\n2. TULUS  user interface\\n2.1 Introduction\\n...   \n",
       "2  \\n2. TULUS  user interface\\n2.1 Introduction\\n...   \n",
       "3  \\n2. TULUS  user interface\\n2.1 Introduction\\n...   \n",
       "4  \\n2. TULUS  user interface\\n2.1 Introduction\\n...   \n",
       "\n",
       "                                            question  \\\n",
       "0    What is the main purpose of the Tulus software?   \n",
       "1  What are some key components of the Tulus user...   \n",
       "2  What functions are available on the vertical t...   \n",
       "3  What information is displayed in the notificat...   \n",
       "4  What kind of controls and information can be f...   \n",
       "\n",
       "                                              answer  \n",
       "0  The main purpose of the Tulus software is to m...  \n",
       "1  Some key components of the Tulus user interfac...  \n",
       "2  The vertical toolbar in the Tulus interface in...  \n",
       "3  The notification area displays messages about ...  \n",
       "4  The \"Customer\" section of the Tulus interface ...  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAGAS Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Faithfulness \n",
    "This measures the factual consistency of the generated answer against the given context. It is calculated from answer and retrieved context. The answer is scaled to (0,1) range. Higher the better.\n",
    "The generated answer is regarded as faithful if all the claims that are made in the answer can be inferred from the given context. To calculate this a set of claims from the generated answer is first identified. Then each one of these claims are cross checked with given context to determine if it can be inferred from given context or not. The faithfulness score is given by divided by (1) \n",
    "\n",
    "Faithfulness score = Number of claims in the generated answer that can be inferred from given context / Total number of claims in the generated answer|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer Relevance\n",
    "\n",
    "The evaluation metric, Answer Relevancy, focuses on assessing how pertinent the generated answer is to the given prompt. A lower score is assigned to answers that are incomplete or contain redundant information and higher scores indicate better relevancy. This metric is computed using the question, the context and the answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Context Precision\n",
    "\n",
    "Context Precision is a metric that evaluates whether all of the ground-truth relevant items present in the contexts are ranked higher or not. Ideally all the relevant chunks must appear at the top ranks. This metric is computed using the question, ground_truth and the contexts, with values ranging between 0 and 1, where higher scores indicate better precision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Context Relevancy\n",
    "\n",
    "This metric gauges the relevancy of the retrieved context, calculated based on both the question and contexts. The values fall within the range of (0, 1), with higher values indicating better relevancy.\n",
    "Ideally, the retrieved context should exclusively contain essential information to address the provided query. To compute this, we initially estimate the value of S| by identifying sentences within the retrieved context that are relevant for answering the given question. The final score is determined by the following formula:\n",
    "\n",
    "context relevancy = |S| / |Total number of sentences in retrieved context|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Context Recall \n",
    "\n",
    "Context recall measures the extent to which the retrieved context aligns with the annotated answer, treated as the ground truth. It is computed based on the ground truth and the retrieved context, and the values range between 0 and 1, with higher values indicating better performance.\n",
    "\n",
    "To estimate context recall from the ground truth answer, each sentence in the ground truth answer is analyzed to determine whether it can be attributed to the retrieved context or not. In an ideal scenario, all sentences in the ground truth answer should be attributable to the retrieved context.\n",
    "\n",
    "The formula for calculating context recall is as follows:\n",
    "\n",
    "\n",
    "context recall = |GT sentences that can be attributed to context| / Number of sentences in GT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer Correctness\n",
    "\n",
    "The assessment of Answer Correctness involves gauging the accuracy of the generated answer when compared to the ground truth. This evaluation relies on the ground truth and the answer, with scores ranging from 0 to 1. A higher score indicates a closer alignment between the generated answer and the ground truth, signifying better correctness.\n",
    "\n",
    "Answer correctness encompasses two critical aspects: semantic similarity between the generated answer and the ground truth, as well as factual similarity. These aspects are combined using a weighted scheme to formulate the answer correctness score. Users also have the option to employ a ‘threshold’ value to round the resulting score to binary, if desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.metrics import (\n",
    "    answer_relevancy,\n",
    "    faithfulness,\n",
    "    context_recall,\n",
    "    context_precision,\n",
    "    context_relevancy,\n",
    "    answer_correctness,\n",
    "    answer_similarity\n",
    ")\n",
    "\n",
    "\n",
    "from ragas.metrics.critique import harmfulness\n",
    "from ragas import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "\n",
    "\n",
    "\n",
    "rag_dataset = []\n",
    "\n",
    "def create_ragas_dataset(df_main,column_name=\"answer\"):\n",
    "  for index, row in tqdm(df_main.iterrows(), total=df_main.shape[0]):\n",
    "    answer, source_docs = get_answer_and_chunks(row[\"question\"])\n",
    "    rag_dataset.append(\n",
    "        {\"question\" : row[\"question\"],\n",
    "         \"answer\" : answer,\n",
    "         \"contexts\" : [context.page_content for context in source_docs],\n",
    "         \"ground_truths\" : [row[column_name]]\n",
    "         }\n",
    "    )\n",
    "  rag_df = pd.DataFrame(rag_dataset)\n",
    "  rag_eval_dataset = Dataset.from_pandas(rag_df)\n",
    "  return rag_eval_dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_ragas_dataset(ragas_dataset):\n",
    "  result = evaluate(\n",
    "    ragas_dataset,\n",
    "    metrics=[\n",
    "        context_precision,\n",
    "        faithfulness,\n",
    "        answer_relevancy,\n",
    "        context_recall,\n",
    "        context_relevancy,\n",
    "        answer_correctness,\n",
    "        answer_similarity\n",
    "    ],\n",
    "  )\n",
    "  return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Set Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   Exception in thread Thread-90:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/hadiibrahim/anaconda3/envs/temp-env/lib/python3.11/site-packages/tqdm/std.py\", line 1191, in __iter__\n",
      "    self.update(n - last_print_n)\n",
      "  File \"/Users/hadiibrahim/anaconda3/envs/temp-env/lib/python3.11/site-packages/tqdm/std.py\", line 1242, in update\n",
      "    self.refresh(lock_args=self.lock_args)\n",
      "  File \"/Users/hadiibrahim/anaconda3/envs/temp-env/lib/python3.11/site-packages/tqdm/std.py\", line 1347, in refresh\n",
      "    self.display()\n",
      "  File \"/Users/hadiibrahim/anaconda3/envs/temp-env/lib/python3.11/site-packages/tqdm/std.py\", line 1495, in display\n",
      "    self.sp(self.__str__() if msg is None else msg)\n",
      "  File \"/Users/hadiibrahim/anaconda3/envs/temp-env/lib/python3.11/site-packages/tqdm/std.py\", line 459, in print_status\n",
      "    fp_write('\\r' + s + (' ' * max(last_len[0] - len_s, 0)))\n",
      "  File \"/Users/hadiibrahim/anaconda3/envs/temp-env/lib/python3.11/site-packages/tqdm/std.py\", line 452, in fp_write\n",
      "    fp.write(str(s))\n",
      "  File \"/Users/hadiibrahim/anaconda3/envs/temp-env/lib/python3.11/site-packages/tqdm/utils.py\", line 196, in inner\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/hadiibrahim/anaconda3/envs/temp-env/lib/python3.11/site-packages/ipykernel/iostream.py\", line 694, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/Users/hadiibrahim/anaconda3/envs/temp-env/lib/python3.11/site-packages/ipykernel/iostream.py\", line 590, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/Users/hadiibrahim/anaconda3/envs/temp-env/lib/python3.11/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/Users/hadiibrahim/anaconda3/envs/temp-env/lib/python3.11/site-packages/zmq/sugar/socket.py\", line 701, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"_zmq.py\", line 1073, in zmq.backend.cython._zmq.Socket.send\n",
      "  File \"_zmq.py\", line 1115, in zmq.backend.cython._zmq.Socket.send\n",
      "  File \"_zmq.py\", line 1190, in zmq.backend.cython._zmq._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/hadiibrahim/anaconda3/envs/temp-env/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/Users/hadiibrahim/anaconda3/envs/temp-env/lib/python3.11/site-packages/ragas/executor.py\", line 96, in run\n",
      "    results = self.loop.run_until_complete(self._aresults())\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/hadiibrahim/anaconda3/envs/temp-env/lib/python3.11/asyncio/base_events.py\", line 654, in run_until_complete\n",
      "    return future.result()\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/hadiibrahim/anaconda3/envs/temp-env/lib/python3.11/site-packages/ragas/executor.py\", line 70, in _aresults\n",
      "    for future in tqdm(\n",
      "  File \"/Users/hadiibrahim/anaconda3/envs/temp-env/lib/python3.11/site-packages/tqdm/std.py\", line 1196, in __iter__\n",
      "    self.close()\n",
      "  File \"/Users/hadiibrahim/anaconda3/envs/temp-env/lib/python3.11/site-packages/tqdm/std.py\", line 1306, in close\n",
      "    if self.display(msg='', pos=pos) and not pos:\n",
      "       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/hadiibrahim/anaconda3/envs/temp-env/lib/python3.11/site-packages/tqdm/std.py\", line 1495, in display\n",
      "    self.sp(self.__str__() if msg is None else msg)\n",
      "  File \"/Users/hadiibrahim/anaconda3/envs/temp-env/lib/python3.11/site-packages/tqdm/std.py\", line 459, in print_status\n",
      "    fp_write('\\r' + s + (' ' * max(last_len[0] - len_s, 0)))\n",
      "  File \"/Users/hadiibrahim/anaconda3/envs/temp-env/lib/python3.11/site-packages/tqdm/std.py\", line 453, in fp_write\n",
      "    fp_flush()\n",
      "  File \"/Users/hadiibrahim/anaconda3/envs/temp-env/lib/python3.11/site-packages/tqdm/utils.py\", line 196, in inner\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/hadiibrahim/anaconda3/envs/temp-env/lib/python3.11/site-packages/ipykernel/iostream.py\", line 604, in flush\n",
      "    self.pub_thread.schedule(self._flush)\n",
      "  File \"/Users/hadiibrahim/anaconda3/envs/temp-env/lib/python3.11/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/Users/hadiibrahim/anaconda3/envs/temp-env/lib/python3.11/site-packages/zmq/sugar/socket.py\", line 701, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"_zmq.py\", line 1073, in zmq.backend.cython._zmq.Socket.send\n",
      "  File \"_zmq.py\", line 1115, in zmq.backend.cython._zmq.Socket.send\n",
      "  File \"_zmq.py\", line 1190, in zmq.backend.cython._zmq._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Exception in threading.excepthook:\n",
      "Exception ignored in thread started by: <bound method Thread._bootstrap of <Runner(Thread-90, stopped 13433225216)>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/hadiibrahim/anaconda3/envs/temp-env/lib/python3.11/threading.py\", line 1002, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/Users/hadiibrahim/anaconda3/envs/temp-env/lib/python3.11/threading.py\", line 1047, in _bootstrap_inner\n",
      "    self._invoke_excepthook(self)\n",
      "  File \"/Users/hadiibrahim/anaconda3/envs/temp-env/lib/python3.11/threading.py\", line 1359, in invoke_excepthook\n",
      "    local_print(\"Exception in threading.excepthook:\",\n",
      "  File \"/Users/hadiibrahim/anaconda3/envs/temp-env/lib/python3.11/site-packages/ipykernel/iostream.py\", line 604, in flush\n",
      "    self.pub_thread.schedule(self._flush)\n",
      "  File \"/Users/hadiibrahim/anaconda3/envs/temp-env/lib/python3.11/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/Users/hadiibrahim/anaconda3/envs/temp-env/lib/python3.11/site-packages/zmq/sugar/socket.py\", line 701, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"_zmq.py\", line 1073, in zmq.backend.cython._zmq.Socket.send\n",
      "  File \"_zmq.py\", line 1115, in zmq.backend.cython._zmq.Socket.send\n",
      "  File \"_zmq.py\", line 1190, in zmq.backend.cython._zmq._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Exception ignored in sys.unraisablehook: <built-in function unraisablehook>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/hadiibrahim/anaconda3/envs/temp-env/lib/python3.11/site-packages/ipykernel/iostream.py\", line 604, in flush\n",
      "    self.pub_thread.schedule(self._flush)\n",
      "  File \"/Users/hadiibrahim/anaconda3/envs/temp-env/lib/python3.11/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/Users/hadiibrahim/anaconda3/envs/temp-env/lib/python3.11/site-packages/zmq/sugar/socket.py\", line 701, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"_zmq.py\", line 1073, in zmq.backend.cython._zmq.Socket.send\n",
      "  File \"_zmq.py\", line 1115, in zmq.backend.cython._zmq.Socket.send\n",
      "  File \"_zmq.py\", line 1190, in zmq.backend.cython._zmq._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n"
     ]
    }
   ],
   "source": [
    "from ragas.testset.generator import TestsetGenerator\n",
    "from ragas.testset.evolutions import simple, reasoning, multi_context\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "# documents = load your documents\n",
    "\n",
    "# generator with openai models\n",
    "generator_llm = ChatOpenAI(model=\"gpt-3.5-turbo-16k\")\n",
    "critic_llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "generator = TestsetGenerator.from_langchain(\n",
    "    generator_llm,\n",
    "    critic_llm,\n",
    "    embeddings\n",
    ")\n",
    "\n",
    "# Change resulting question type distribution\n",
    "distributions = {\n",
    "    simple: 0.5,\n",
    "    multi_context: 0.4,\n",
    "    reasoning: 0.1\n",
    "}\n",
    "\n",
    "# use generator.generate_with_llamaindex_docs if you use llama-index as document loader\n",
    "testset = generator.generate_with_langchain_docs(docs, 6000, distributions) \n",
    "testset.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3=pd.DataFrame(testset.to_pandas())\n",
    "df3.to_csv(\"testset.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [03:50<00:00, 23.00s/it]\n"
     ]
    }
   ],
   "source": [
    "basic_qa_ragas_dataset = create_ragas_dataset(pd.DataFrame(testset.to_pandas()),\"ground_truth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>contexts</th>\n",
       "      <th>ground_truths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What are the different functional areas within...</td>\n",
       "      <td>Based on the provided screenshots and descript...</td>\n",
       "      <td>[On the topleft there is a vertical navigation...</td>\n",
       "      <td>[The different functional areas within the app...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What can be accessed through the separate menu...</td>\n",
       "      <td>Through the separate menu in the Tulus system ...</td>\n",
       "      <td>[6. TULUS  System management and settings\\nThe...</td>\n",
       "      <td>[The tools needed for general management of th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is the purpose of the dropdown menus in t...</td>\n",
       "      <td>The purpose of the dropdown menus in the inter...</td>\n",
       "      <td>[The interface is divided into several section...</td>\n",
       "      <td>[The purpose of the dropdown menus in the inte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is the current status of the FPServiceBro...</td>\n",
       "      <td>The current status of the FPServiceBroker serv...</td>\n",
       "      <td>[The image appears to be a screenshot of a gra...</td>\n",
       "      <td>[The current status of the FPServiceBroker ser...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the purpose of the hierarchical struct...</td>\n",
       "      <td>The purpose of the hierarchical structure in t...</td>\n",
       "      <td>[On the top left corner there is a menu bar wi...</td>\n",
       "      <td>[The purpose of the hierarchical structure in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What does the license management tool do in th...</td>\n",
       "      <td>The license management tool in the software in...</td>\n",
       "      <td>[An activated license is valid only for the so...</td>\n",
       "      <td>[The license management tool in the software i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What is the purpose of the main menu in the so...</td>\n",
       "      <td>The main menu in the software for laser operat...</td>\n",
       "      <td>[laser. 2 Play/Stop Button Start/stop a task l...</td>\n",
       "      <td>[The main menu in the software for laser opera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>What does the Cancel button do in the producti...</td>\n",
       "      <td>The Cancel button in the production order mana...</td>\n",
       "      <td>[At the bottom there are two buttons Add highl...</td>\n",
       "      <td>[The Cancel button allows the user to exit wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>What is the purpose of MDA mode in the control...</td>\n",
       "      <td>According to the text, MDA mode allows to run ...</td>\n",
       "      <td>[The center of the interface displays operatio...</td>\n",
       "      <td>[MDA mode allows for running utility programs ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>How does the hierarchical structure in the nav...</td>\n",
       "      <td>The hierarchical structure in the navigation p...</td>\n",
       "      <td>[On the top left corner there is a menu bar wi...</td>\n",
       "      <td>[The hierarchical structure in the navigation ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  What are the different functional areas within...   \n",
       "1  What can be accessed through the separate menu...   \n",
       "2  What is the purpose of the dropdown menus in t...   \n",
       "3  What is the current status of the FPServiceBro...   \n",
       "4  What is the purpose of the hierarchical struct...   \n",
       "5  What does the license management tool do in th...   \n",
       "6  What is the purpose of the main menu in the so...   \n",
       "7  What does the Cancel button do in the producti...   \n",
       "8  What is the purpose of MDA mode in the control...   \n",
       "9  How does the hierarchical structure in the nav...   \n",
       "\n",
       "                                              answer  \\\n",
       "0  Based on the provided screenshots and descript...   \n",
       "1  Through the separate menu in the Tulus system ...   \n",
       "2  The purpose of the dropdown menus in the inter...   \n",
       "3  The current status of the FPServiceBroker serv...   \n",
       "4  The purpose of the hierarchical structure in t...   \n",
       "5  The license management tool in the software in...   \n",
       "6  The main menu in the software for laser operat...   \n",
       "7  The Cancel button in the production order mana...   \n",
       "8  According to the text, MDA mode allows to run ...   \n",
       "9  The hierarchical structure in the navigation p...   \n",
       "\n",
       "                                            contexts  \\\n",
       "0  [On the topleft there is a vertical navigation...   \n",
       "1  [6. TULUS  System management and settings\\nThe...   \n",
       "2  [The interface is divided into several section...   \n",
       "3  [The image appears to be a screenshot of a gra...   \n",
       "4  [On the top left corner there is a menu bar wi...   \n",
       "5  [An activated license is valid only for the so...   \n",
       "6  [laser. 2 Play/Stop Button Start/stop a task l...   \n",
       "7  [At the bottom there are two buttons Add highl...   \n",
       "8  [The center of the interface displays operatio...   \n",
       "9  [On the top left corner there is a menu bar wi...   \n",
       "\n",
       "                                       ground_truths  \n",
       "0  [The different functional areas within the app...  \n",
       "1  [The tools needed for general management of th...  \n",
       "2  [The purpose of the dropdown menus in the inte...  \n",
       "3  [The current status of the FPServiceBroker ser...  \n",
       "4  [The purpose of the hierarchical structure in ...  \n",
       "5  [The license management tool in the software i...  \n",
       "6  [The main menu in the software for laser opera...  \n",
       "7  [The Cancel button allows the user to exit wit...  \n",
       "8  [MDA mode allows for running utility programs ...  \n",
       "9  [The hierarchical structure in the navigation ...  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_qa_ragas_dataset.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating: 100%|██████████| 70/70 [01:56<00:00,  1.66s/it]\n"
     ]
    }
   ],
   "source": [
    "basic_qa_result = evaluate_ragas_dataset(basic_qa_ragas_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context_precision': 0.9917, 'faithfulness': 0.7871, 'answer_relevancy': 0.9716, 'context_recall': 1.0000, 'context_relevancy': 0.0255, 'answer_correctness': 0.6130, 'answer_similarity': 0.9552}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_qa_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating: 100%|██████████| 70/70 [02:33<00:00,  2.19s/it]\n"
     ]
    }
   ],
   "source": [
    "basic_qa_result = evaluate_ragas_dataset(basic_qa_ragas_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context_precision': 0.9833, 'faithfulness': 0.9583, 'answer_relevancy': 0.9720, 'context_recall': 0.9000, 'context_relevancy': 0.0325, 'answer_correctness': 0.6566, 'answer_similarity': 0.9558}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_qa_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import logging\n",
    "import json\n",
    "import pickle\n",
    "from dotenv import load_dotenv\n",
    "from langchain.vectorstores import Chroma, FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.llms import HuggingFaceHub\n",
    "from langchain_groq import ChatGroq\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from ragas.testset.generator import TestsetGenerator\n",
    "from ragas.testset.evolutions import simple, reasoning, multi_context\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from ragas.metrics import (\n",
    "    answer_relevancy,\n",
    "    faithfulness,\n",
    "    context_recall,\n",
    "    context_precision,\n",
    "    context_relevancy,\n",
    "    answer_correctness,\n",
    "    answer_similarity,\n",
    ")\n",
    "from langchain.retrievers.document_compressors import FlashrankRerank\n",
    "from ragas.metrics.critique import harmfulness\n",
    "from ragas import evaluate\n",
    "from ragatouille import RAGPretrainedModel\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Ensure the correct forward reference\n",
    "# FlashrankRerank.update_forward_refs(Ranker=RankerModel)\n",
    "\n",
    "# Now, you can use the FlashrankRerank with the RankerModel\n",
    "compressor = FlashrankRerank(model_name=\"ms-marco-MultiBERT-L-12\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for FlashrankRerank\nclient\n  instance of RankerModel expected (type=type_error.arbitrary_type; expected_arbitrary_type=RankerModel)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mretrievers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocument_compressors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FlashrankRerank\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_openai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ChatOpenAI\n\u001b[0;32m----> 5\u001b[0m compressor \u001b[38;5;241m=\u001b[39m \u001b[43mFlashrankRerank\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m compression_retriever \u001b[38;5;241m=\u001b[39m ContextualCompressionRetriever(\n\u001b[1;32m      7\u001b[0m     base_compressor\u001b[38;5;241m=\u001b[39mcompressor, base_retriever\u001b[38;5;241m=\u001b[39mretriever\n\u001b[1;32m      8\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/temp-env/lib/python3.11/site-packages/pydantic/v1/main.py:341\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[0;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[1;32m    339\u001b[0m values, fields_set, validation_error \u001b[38;5;241m=\u001b[39m validate_model(__pydantic_self__\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m, data)\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validation_error:\n\u001b[0;32m--> 341\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m validation_error\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    343\u001b[0m     object_setattr(__pydantic_self__, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__dict__\u001b[39m\u001b[38;5;124m'\u001b[39m, values)\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for FlashrankRerank\nclient\n  instance of RankerModel expected (type=type_error.arbitrary_type; expected_arbitrary_type=RankerModel)"
     ]
    }
   ],
   "source": [
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import FlashrankRerank\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "compressor = FlashrankRerank()\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor, base_retriever=retriever\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flashrank import Ranker, RerankRequest\n",
    "\n",
    "# Small (~34MB), slightly slower & best performance (ranking precision).\n",
    "ranker = Ranker(model_name=\"ms-marco-MiniLM-L-12-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "from flashrank import Ranker, RerankRequest\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from dotenv import load_dotenv\n",
    "from langchain_cohere import CohereRerank\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "COHERE_API_KEY = os.getenv(\"COHERE_API_KEY\")\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "vector_store = FAISS.from_documents(docs, embeddings)\n",
    "\n",
    "retriever = vector_store.as_retriever(\n",
    "            search_type=\"similarity\", search_kwargs={\"k\": 10})\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "HUGGINGFACE_API_TOKEN=os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")\n",
    "groq_api_key=os.getenv(\"GRORQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma, FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "from langchain_community.llms import HuggingFaceHub\n",
    "from langchain_groq import ChatGroq\n",
    "import pickle\n",
    "\n",
    "llm=ChatGroq(groq_api_key=groq_api_key, model_name='llama3-70b-8192')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "result = llm.invoke(\"what is the capital of France\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma, FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "from langchain_community.llms import HuggingFaceHub\n",
    "from langchain_groq import ChatGroq\n",
    "import pickle\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "os.environ['HUGGINGFACEHUB_API_TOKEN']=os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")\n",
    "groq_api_key = os.environ[\"GROQ_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hadiibrahim/anaconda3/envs/temp-env/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `HuggingFaceHub` was deprecated in LangChain 0.0.21 and will be removed in 0.3.0. Use HuggingFaceEndpoint instead.\n",
      "  warn_deprecated(\n",
      "/Users/hadiibrahim/anaconda3/envs/temp-env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "hf=HuggingFaceHub(\n",
    "    repo_id=\"meta-llama/Meta-Llama-3-70B\",\n",
    "    model_kwargs={\"temperature\":0.1}\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(groq_api_key=groq_api_key,model_name=\"llama3-70b-8192\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_file = \"/Users/hadiibrahim/Dev/prima-power-hmi-assistant/data/chunks.pkl\"\n",
    "with open(pickle_file, \"rb\") as file:\n",
    "    docs_manual = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_file = \"/Users/hadiibrahim/Dev/prima-power-hmi-assistant/data/alarm_info_list.pkl\"\n",
    "with open(pickle_file, \"rb\") as file:\n",
    "    docs_alarm = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_list = docs_manual + docs_alarm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3315"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "len(docs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.docstore.document import Document\n",
    "\n",
    "documents_manual = [\n",
    "    Document(page_content=text, metadata={\"source\": \"TULUS manual software\"})\n",
    "    for text in docs_manual\n",
    "]\n",
    "\n",
    "documents_alarm = [\n",
    "    Document(page_content=text, metadata={\"source\": \"TULUS - Alarms\"})\n",
    "    for text in docs_alarm\n",
    "]\n",
    "\n",
    "docs = documents_manual + documents_alarm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_pickle_file = \"docs.pkl\"\n",
    "with open(output_pickle_file, 'wb') as f:\n",
    "    # Dump the concatenated list into the pickle file\n",
    "    pickle.dump(docs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the embeddings and vector store\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "\n",
    "vector_store_chroma = Chroma.from_documents(docs,embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store_faiss = FAISS.from_documents(docs,embeddings)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a prompt template for the language model\n",
    "prompt_template = PromptTemplate(input_variables=[\"context\", \"question\"],\n",
    "                                 template=\"Given the following context: {context}, answer the question: {question}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever=vector_store_chroma.as_retriever(search_type=\"similarity\",search_kwargs={\"k\":4})\n",
    "# retriever=vector_store_chroma.as_retriever(search_type=\"similarity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "retrievalQA=RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\":prompt_template}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: There are 4 Alarm IDs mentioned in the provided context:\n",
      "\n",
      "1. Alarm ID: 32/147\n",
      "2. Alarm ID: 352\n",
      "3. Alarm ID: 22/44\n",
      "4. Alarm ID: 0/1282\n",
      "Chunks Used:\n",
      "Document : 0\n",
      "Metadata: {'source': 'TULUS - Alarms'}\n",
      "\n",
      "Document : 1\n",
      "Metadata: {'source': 'TULUS - Alarms'}\n",
      "\n",
      "Document : 2\n",
      "Metadata: {'source': 'TULUS - Alarms'}\n",
      "\n",
      "Document : 3\n",
      "Metadata: {'source': 'TULUS - Alarms'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Function to retrieve answer and chunks used\n",
    "def get_answer_and_chunks(query):\n",
    "    # Use the qa_chain to get the answer and source documents\n",
    "    \n",
    "    result = retrievalQA.invoke({\"query\": query})\n",
    "    \n",
    "    # Extract the answer and source documents\n",
    "    answer = result[\"result\"]\n",
    "    source_documents = result[\"source_documents\"]\n",
    "    \n",
    "    return answer, source_documents\n",
    "\n",
    "# Define a query and retrieve the answer along with chunks\n",
    "query = \"how many alari Ids are there in tulus\"\n",
    "answer, source_docs = get_answer_and_chunks(query)\n",
    "\n",
    "print(\"Answer:\", answer)\n",
    "print(\"Chunks Used:\")\n",
    "\n",
    "\n",
    "if source_docs:\n",
    "    for index,chunk in enumerate(source_docs):\n",
    "        print(\"Document :\", index)\n",
    "        # print(chunk.page_content)\n",
    "        print(\"Metadata:\", chunk.metadata)\n",
    "        print()\n",
    "else:\n",
    "    print(\"No chunks used\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## replace index in original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "file_path='/Users/hadiibrahim/Dev/prima-power-hmi-assistant/src/data/main_manual_file_with_index (1).csv'\n",
    "df=pd.read_csv(file_path,sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_file = \"/Users/hadiibrahim/Dev/prima-power-hmi-assistant/data/chunks.pkl\"\n",
    "with open(pickle_file, \"rb\") as file:\n",
    "    chunks = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_context(df, new_context_list):\n",
    "    # Replace each context value based on the context_index\n",
    "    df['context'] = df['closest_text_index'].apply(lambda x: new_context_list[x])\n",
    "    return df\n",
    "\n",
    "# Apply the function\n",
    "df = replace_context(df, chunks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main= df.drop(columns=[\"correct_answers\",\"incorrect_answers\",\"closest_text_index\",\"category\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main.rename(columns={\"best_answer\":\"answer\"},inplace=True)\n",
    "df_main.rename(columns={\"context\":\"contexts\"},inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contexts</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n2. TULUS  user interface\\n2.1 Introduction\\n...</td>\n",
       "      <td>What is the main purpose of the Tulus software?</td>\n",
       "      <td>The main purpose of the Tulus software is to m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n2. TULUS  user interface\\n2.1 Introduction\\n...</td>\n",
       "      <td>What are some key components of the Tulus user...</td>\n",
       "      <td>Some key components of the Tulus user interfac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n2. TULUS  user interface\\n2.1 Introduction\\n...</td>\n",
       "      <td>What functions are available on the vertical t...</td>\n",
       "      <td>The vertical toolbar in the Tulus interface in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\n2. TULUS  user interface\\n2.1 Introduction\\n...</td>\n",
       "      <td>What information is displayed in the notificat...</td>\n",
       "      <td>The notification area displays messages about ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\n2. TULUS  user interface\\n2.1 Introduction\\n...</td>\n",
       "      <td>What kind of controls and information can be f...</td>\n",
       "      <td>The \"Customer\" section of the Tulus interface ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            contexts  \\\n",
       "0  \\n2. TULUS  user interface\\n2.1 Introduction\\n...   \n",
       "1  \\n2. TULUS  user interface\\n2.1 Introduction\\n...   \n",
       "2  \\n2. TULUS  user interface\\n2.1 Introduction\\n...   \n",
       "3  \\n2. TULUS  user interface\\n2.1 Introduction\\n...   \n",
       "4  \\n2. TULUS  user interface\\n2.1 Introduction\\n...   \n",
       "\n",
       "                                            question  \\\n",
       "0    What is the main purpose of the Tulus software?   \n",
       "1  What are some key components of the Tulus user...   \n",
       "2  What functions are available on the vertical t...   \n",
       "3  What information is displayed in the notificat...   \n",
       "4  What kind of controls and information can be f...   \n",
       "\n",
       "                                              answer  \n",
       "0  The main purpose of the Tulus software is to m...  \n",
       "1  Some key components of the Tulus user interfac...  \n",
       "2  The vertical toolbar in the Tulus interface in...  \n",
       "3  The notification area displays messages about ...  \n",
       "4  The \"Customer\" section of the Tulus interface ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAGAS Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Faithfulness \n",
    "This measures the factual consistency of the generated answer against the given context. It is calculated from answer and retrieved context. The answer is scaled to (0,1) range. Higher the better.\n",
    "The generated answer is regarded as faithful if all the claims that are made in the answer can be inferred from the given context. To calculate this a set of claims from the generated answer is first identified. Then each one of these claims are cross checked with given context to determine if it can be inferred from given context or not. The faithfulness score is given by divided by (1) \n",
    "\n",
    "Faithfulness score = Number of claims in the generated answer that can be inferred from given context / Total number of claims in the generated answer|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer Relevance\n",
    "\n",
    "The evaluation metric, Answer Relevancy, focuses on assessing how pertinent the generated answer is to the given prompt. A lower score is assigned to answers that are incomplete or contain redundant information and higher scores indicate better relevancy. This metric is computed using the question, the context and the answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Context Precision\n",
    "\n",
    "Context Precision is a metric that evaluates whether all of the ground-truth relevant items present in the contexts are ranked higher or not. Ideally all the relevant chunks must appear at the top ranks. This metric is computed using the question, ground_truth and the contexts, with values ranging between 0 and 1, where higher scores indicate better precision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Context Relevancy\n",
    "\n",
    "This metric gauges the relevancy of the retrieved context, calculated based on both the question and contexts. The values fall within the range of (0, 1), with higher values indicating better relevancy.\n",
    "Ideally, the retrieved context should exclusively contain essential information to address the provided query. To compute this, we initially estimate the value of S| by identifying sentences within the retrieved context that are relevant for answering the given question. The final score is determined by the following formula:\n",
    "\n",
    "context relevancy = |S| / |Total number of sentences in retrieved context|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Context Recall \n",
    "\n",
    "Context recall measures the extent to which the retrieved context aligns with the annotated answer, treated as the ground truth. It is computed based on the ground truth and the retrieved context, and the values range between 0 and 1, with higher values indicating better performance.\n",
    "\n",
    "To estimate context recall from the ground truth answer, each sentence in the ground truth answer is analyzed to determine whether it can be attributed to the retrieved context or not. In an ideal scenario, all sentences in the ground truth answer should be attributable to the retrieved context.\n",
    "\n",
    "The formula for calculating context recall is as follows:\n",
    "\n",
    "\n",
    "context recall = |GT sentences that can be attributed to context| / Number of sentences in GT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer Correctness\n",
    "\n",
    "The assessment of Answer Correctness involves gauging the accuracy of the generated answer when compared to the ground truth. This evaluation relies on the ground truth and the answer, with scores ranging from 0 to 1. A higher score indicates a closer alignment between the generated answer and the ground truth, signifying better correctness.\n",
    "\n",
    "Answer correctness encompasses two critical aspects: semantic similarity between the generated answer and the ground truth, as well as factual similarity. These aspects are combined using a weighted scheme to formulate the answer correctness score. Users also have the option to employ a ‘threshold’ value to round the resulting score to binary, if desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.metrics import (\n",
    "    answer_relevancy,\n",
    "    faithfulness,\n",
    "    context_recall,\n",
    "    context_precision,\n",
    "    context_relevancy,\n",
    "    answer_correctness,\n",
    "    answer_similarity\n",
    ")\n",
    "\n",
    "\n",
    "from ragas.metrics.critique import harmfulness\n",
    "from ragas import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "\n",
    "\n",
    "\n",
    "rag_dataset = []\n",
    "\n",
    "def create_ragas_dataset(df_main,column_name=\"answer\"):\n",
    "  for index, row in tqdm(df_main.iterrows(), total=df_main.shape[0]):\n",
    "    answer, source_docs = get_answer_and_chunks(row[\"question\"])\n",
    "    rag_dataset.append(\n",
    "        {\"question\" : row[\"question\"],\n",
    "         \"answer\" : answer,\n",
    "         \"contexts\" : [context.page_content for context in source_docs],\n",
    "         \"ground_truths\" : [row[column_name]]\n",
    "         }\n",
    "    )\n",
    "  rag_df = pd.DataFrame(rag_dataset)\n",
    "  rag_eval_dataset = Dataset.from_pandas(rag_df)\n",
    "  return rag_eval_dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_ragas_dataset(ragas_dataset):\n",
    "  result = evaluate(\n",
    "    ragas_dataset,\n",
    "    metrics=[\n",
    "        context_precision,\n",
    "        faithfulness,\n",
    "        answer_relevancy,\n",
    "        context_recall,\n",
    "        context_relevancy,\n",
    "        answer_correctness,\n",
    "        answer_similarity\n",
    "    ],\n",
    "  )\n",
    "  return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Set Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle_file = \"/Users/hadiibrahim/Dev/prima-power-hmi-assistant/src/docs.pkl\"\n",
    "with open(pickle_file, \"rb\") as file:\n",
    "    docs = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   Exception in thread Thread-90:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/hadiibrahim/anaconda3/envs/temp-env/lib/python3.11/site-packages/tqdm/std.py\", line 1191, in __iter__\n",
      "    self.update(n - last_print_n)\n",
      "  File \"/Users/hadiibrahim/anaconda3/envs/temp-env/lib/python3.11/site-packages/tqdm/std.py\", line 1242, in update\n",
      "    self.refresh(lock_args=self.lock_args)\n",
      "  File \"/Users/hadiibrahim/anaconda3/envs/temp-env/lib/python3.11/site-packages/tqdm/std.py\", line 1347, in refresh\n",
      "    self.display()\n",
      "  File \"/Users/hadiibrahim/anaconda3/envs/temp-env/lib/python3.11/site-packages/tqdm/std.py\", line 1495, in display\n",
      "    self.sp(self.__str__() if msg is None else msg)\n",
      "  File \"/Users/hadiibrahim/anaconda3/envs/temp-env/lib/python3.11/site-packages/tqdm/std.py\", line 459, in print_status\n",
      "    fp_write('\\r' + s + (' ' * max(last_len[0] - len_s, 0)))\n",
      "  File \"/Users/hadiibrahim/anaconda3/envs/temp-env/lib/python3.11/site-packages/tqdm/std.py\", line 452, in fp_write\n",
      "    fp.write(str(s))\n",
      "  File \"/Users/hadiibrahim/anaconda3/envs/temp-env/lib/python3.11/site-packages/tqdm/utils.py\", line 196, in inner\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/hadiibrahim/anaconda3/envs/temp-env/lib/python3.11/site-packages/ipykernel/iostream.py\", line 694, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/Users/hadiibrahim/anaconda3/envs/temp-env/lib/python3.11/site-packages/ipykernel/iostream.py\", line 590, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/Users/hadiibrahim/anaconda3/envs/temp-env/lib/python3.11/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/Users/hadiibrahim/anaconda3/envs/temp-env/lib/python3.11/site-packages/zmq/sugar/socket.py\", line 701, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"_zmq.py\", line 1073, in zmq.backend.cython._zmq.Socket.send\n",
      "  File \"_zmq.py\", line 1115, in zmq.backend.cython._zmq.Socket.send\n",
      "  File \"_zmq.py\", line 1190, in zmq.backend.cython._zmq._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/hadiibrahim/anaconda3/envs/temp-env/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/Users/hadiibrahim/anaconda3/envs/temp-env/lib/python3.11/site-packages/ragas/executor.py\", line 96, in run\n",
      "    results = self.loop.run_until_complete(self._aresults())\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/hadiibrahim/anaconda3/envs/temp-env/lib/python3.11/asyncio/base_events.py\", line 654, in run_until_complete\n",
      "    return future.result()\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/hadiibrahim/anaconda3/envs/temp-env/lib/python3.11/site-packages/ragas/executor.py\", line 70, in _aresults\n",
      "    for future in tqdm(\n",
      "  File \"/Users/hadiibrahim/anaconda3/envs/temp-env/lib/python3.11/site-packages/tqdm/std.py\", line 1196, in __iter__\n",
      "    self.close()\n",
      "  File \"/Users/hadiibrahim/anaconda3/envs/temp-env/lib/python3.11/site-packages/tqdm/std.py\", line 1306, in close\n",
      "    if self.display(msg='', pos=pos) and not pos:\n",
      "       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/hadiibrahim/anaconda3/envs/temp-env/lib/python3.11/site-packages/tqdm/std.py\", line 1495, in display\n",
      "    self.sp(self.__str__() if msg is None else msg)\n",
      "  File \"/Users/hadiibrahim/anaconda3/envs/temp-env/lib/python3.11/site-packages/tqdm/std.py\", line 459, in print_status\n",
      "    fp_write('\\r' + s + (' ' * max(last_len[0] - len_s, 0)))\n",
      "  File \"/Users/hadiibrahim/anaconda3/envs/temp-env/lib/python3.11/site-packages/tqdm/std.py\", line 453, in fp_write\n",
      "    fp_flush()\n",
      "  File \"/Users/hadiibrahim/anaconda3/envs/temp-env/lib/python3.11/site-packages/tqdm/utils.py\", line 196, in inner\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/hadiibrahim/anaconda3/envs/temp-env/lib/python3.11/site-packages/ipykernel/iostream.py\", line 604, in flush\n",
      "    self.pub_thread.schedule(self._flush)\n",
      "  File \"/Users/hadiibrahim/anaconda3/envs/temp-env/lib/python3.11/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/Users/hadiibrahim/anaconda3/envs/temp-env/lib/python3.11/site-packages/zmq/sugar/socket.py\", line 701, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"_zmq.py\", line 1073, in zmq.backend.cython._zmq.Socket.send\n",
      "  File \"_zmq.py\", line 1115, in zmq.backend.cython._zmq.Socket.send\n",
      "  File \"_zmq.py\", line 1190, in zmq.backend.cython._zmq._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Exception in threading.excepthook:\n",
      "Exception ignored in thread started by: <bound method Thread._bootstrap of <Runner(Thread-90, stopped 13433225216)>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/hadiibrahim/anaconda3/envs/temp-env/lib/python3.11/threading.py\", line 1002, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/Users/hadiibrahim/anaconda3/envs/temp-env/lib/python3.11/threading.py\", line 1047, in _bootstrap_inner\n",
      "    self._invoke_excepthook(self)\n",
      "  File \"/Users/hadiibrahim/anaconda3/envs/temp-env/lib/python3.11/threading.py\", line 1359, in invoke_excepthook\n",
      "    local_print(\"Exception in threading.excepthook:\",\n",
      "  File \"/Users/hadiibrahim/anaconda3/envs/temp-env/lib/python3.11/site-packages/ipykernel/iostream.py\", line 604, in flush\n",
      "    self.pub_thread.schedule(self._flush)\n",
      "  File \"/Users/hadiibrahim/anaconda3/envs/temp-env/lib/python3.11/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/Users/hadiibrahim/anaconda3/envs/temp-env/lib/python3.11/site-packages/zmq/sugar/socket.py\", line 701, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"_zmq.py\", line 1073, in zmq.backend.cython._zmq.Socket.send\n",
      "  File \"_zmq.py\", line 1115, in zmq.backend.cython._zmq.Socket.send\n",
      "  File \"_zmq.py\", line 1190, in zmq.backend.cython._zmq._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Exception ignored in sys.unraisablehook: <built-in function unraisablehook>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/hadiibrahim/anaconda3/envs/temp-env/lib/python3.11/site-packages/ipykernel/iostream.py\", line 604, in flush\n",
      "    self.pub_thread.schedule(self._flush)\n",
      "  File \"/Users/hadiibrahim/anaconda3/envs/temp-env/lib/python3.11/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/Users/hadiibrahim/anaconda3/envs/temp-env/lib/python3.11/site-packages/zmq/sugar/socket.py\", line 701, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"_zmq.py\", line 1073, in zmq.backend.cython._zmq.Socket.send\n",
      "  File \"_zmq.py\", line 1115, in zmq.backend.cython._zmq.Socket.send\n",
      "  File \"_zmq.py\", line 1190, in zmq.backend.cython._zmq._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n"
     ]
    }
   ],
   "source": [
    "from ragas.testset.generator import TestsetGenerator\n",
    "from ragas.testset.evolutions import simple, reasoning, multi_context\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "# documents = load your documents\n",
    "\n",
    "# generator with openai models\n",
    "generator_llm = ChatOpenAI(model=\"gpt-3.5-turbo-16k\")\n",
    "critic_llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "generator = TestsetGenerator.from_langchain(\n",
    "    generator_llm,\n",
    "    critic_llm,\n",
    "    embeddings\n",
    ")\n",
    "\n",
    "# Change resulting question type distribution\n",
    "distributions = {\n",
    "    simple: 0.5,\n",
    "    multi_context: 0.4,\n",
    "    reasoning: 0.1\n",
    "}\n",
    "\n",
    "# use generator.generate_with_llamaindex_docs if you use llama-index as document loader\n",
    "testset = generator.generate_with_langchain_docs(docs, 6000, distributions) \n",
    "testset.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3=pd.DataFrame(testset.to_pandas())\n",
    "df3.to_csv(\"testset.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [03:50<00:00, 23.00s/it]\n"
     ]
    }
   ],
   "source": [
    "basic_qa_ragas_dataset = create_ragas_dataset(pd.DataFrame(testset.to_pandas()),\"ground_truth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>contexts</th>\n",
       "      <th>ground_truths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What are the different functional areas within...</td>\n",
       "      <td>Based on the provided screenshots and descript...</td>\n",
       "      <td>[On the topleft there is a vertical navigation...</td>\n",
       "      <td>[The different functional areas within the app...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What can be accessed through the separate menu...</td>\n",
       "      <td>Through the separate menu in the Tulus system ...</td>\n",
       "      <td>[6. TULUS  System management and settings\\nThe...</td>\n",
       "      <td>[The tools needed for general management of th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is the purpose of the dropdown menus in t...</td>\n",
       "      <td>The purpose of the dropdown menus in the inter...</td>\n",
       "      <td>[The interface is divided into several section...</td>\n",
       "      <td>[The purpose of the dropdown menus in the inte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is the current status of the FPServiceBro...</td>\n",
       "      <td>The current status of the FPServiceBroker serv...</td>\n",
       "      <td>[The image appears to be a screenshot of a gra...</td>\n",
       "      <td>[The current status of the FPServiceBroker ser...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the purpose of the hierarchical struct...</td>\n",
       "      <td>The purpose of the hierarchical structure in t...</td>\n",
       "      <td>[On the top left corner there is a menu bar wi...</td>\n",
       "      <td>[The purpose of the hierarchical structure in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What does the license management tool do in th...</td>\n",
       "      <td>The license management tool in the software in...</td>\n",
       "      <td>[An activated license is valid only for the so...</td>\n",
       "      <td>[The license management tool in the software i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What is the purpose of the main menu in the so...</td>\n",
       "      <td>The main menu in the software for laser operat...</td>\n",
       "      <td>[laser. 2 Play/Stop Button Start/stop a task l...</td>\n",
       "      <td>[The main menu in the software for laser opera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>What does the Cancel button do in the producti...</td>\n",
       "      <td>The Cancel button in the production order mana...</td>\n",
       "      <td>[At the bottom there are two buttons Add highl...</td>\n",
       "      <td>[The Cancel button allows the user to exit wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>What is the purpose of MDA mode in the control...</td>\n",
       "      <td>According to the text, MDA mode allows to run ...</td>\n",
       "      <td>[The center of the interface displays operatio...</td>\n",
       "      <td>[MDA mode allows for running utility programs ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>How does the hierarchical structure in the nav...</td>\n",
       "      <td>The hierarchical structure in the navigation p...</td>\n",
       "      <td>[On the top left corner there is a menu bar wi...</td>\n",
       "      <td>[The hierarchical structure in the navigation ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  What are the different functional areas within...   \n",
       "1  What can be accessed through the separate menu...   \n",
       "2  What is the purpose of the dropdown menus in t...   \n",
       "3  What is the current status of the FPServiceBro...   \n",
       "4  What is the purpose of the hierarchical struct...   \n",
       "5  What does the license management tool do in th...   \n",
       "6  What is the purpose of the main menu in the so...   \n",
       "7  What does the Cancel button do in the producti...   \n",
       "8  What is the purpose of MDA mode in the control...   \n",
       "9  How does the hierarchical structure in the nav...   \n",
       "\n",
       "                                              answer  \\\n",
       "0  Based on the provided screenshots and descript...   \n",
       "1  Through the separate menu in the Tulus system ...   \n",
       "2  The purpose of the dropdown menus in the inter...   \n",
       "3  The current status of the FPServiceBroker serv...   \n",
       "4  The purpose of the hierarchical structure in t...   \n",
       "5  The license management tool in the software in...   \n",
       "6  The main menu in the software for laser operat...   \n",
       "7  The Cancel button in the production order mana...   \n",
       "8  According to the text, MDA mode allows to run ...   \n",
       "9  The hierarchical structure in the navigation p...   \n",
       "\n",
       "                                            contexts  \\\n",
       "0  [On the topleft there is a vertical navigation...   \n",
       "1  [6. TULUS  System management and settings\\nThe...   \n",
       "2  [The interface is divided into several section...   \n",
       "3  [The image appears to be a screenshot of a gra...   \n",
       "4  [On the top left corner there is a menu bar wi...   \n",
       "5  [An activated license is valid only for the so...   \n",
       "6  [laser. 2 Play/Stop Button Start/stop a task l...   \n",
       "7  [At the bottom there are two buttons Add highl...   \n",
       "8  [The center of the interface displays operatio...   \n",
       "9  [On the top left corner there is a menu bar wi...   \n",
       "\n",
       "                                       ground_truths  \n",
       "0  [The different functional areas within the app...  \n",
       "1  [The tools needed for general management of th...  \n",
       "2  [The purpose of the dropdown menus in the inte...  \n",
       "3  [The current status of the FPServiceBroker ser...  \n",
       "4  [The purpose of the hierarchical structure in ...  \n",
       "5  [The license management tool in the software i...  \n",
       "6  [The main menu in the software for laser opera...  \n",
       "7  [The Cancel button allows the user to exit wit...  \n",
       "8  [MDA mode allows for running utility programs ...  \n",
       "9  [The hierarchical structure in the navigation ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "basic_qa_ragas_dataset.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating: 100%|██████████| 70/70 [01:56<00:00,  1.66s/it]\n"
     ]
    }
   ],
   "source": [
    "basic_qa_result = evaluate_ragas_dataset(basic_qa_ragas_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context_precision': 0.9917, 'faithfulness': 0.7871, 'answer_relevancy': 0.9716, 'context_recall': 1.0000, 'context_relevancy': 0.0255, 'answer_correctness': 0.6130, 'answer_similarity': 0.9552}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "basic_qa_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating: 100%|██████████| 70/70 [02:33<00:00,  2.19s/it]\n"
     ]
    }
   ],
   "source": [
    "basic_qa_result = evaluate_ragas_dataset(basic_qa_ragas_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context_precision': 0.9833, 'faithfulness': 0.9583, 'answer_relevancy': 0.9720, 'context_recall': 0.9000, 'context_relevancy': 0.0325, 'answer_correctness': 0.6566, 'answer_similarity': 0.9558}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "basic_qa_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import logging\n",
    "import json\n",
    "import pickle\n",
    "from dotenv import load_dotenv\n",
    "from langchain.vectorstores import Chroma, FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.llms import HuggingFaceHub\n",
    "from langchain_groq import ChatGroq\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from ragas.testset.generator import TestsetGenerator\n",
    "from ragas.testset.evolutions import simple, reasoning, multi_context\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from ragas.metrics import (\n",
    "    answer_relevancy,\n",
    "    faithfulness,\n",
    "    context_recall,\n",
    "    context_precision,\n",
    "    context_relevancy,\n",
    "    answer_correctness,\n",
    "    answer_similarity,\n",
    ")\n",
    "from langchain.retrievers.document_compressors import FlashrankRerank\n",
    "from ragas.metrics.critique import harmfulness\n",
    "from ragas import evaluate\n",
    "from ragatouille import RAGPretrainedModel\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Ensure the correct forward reference\n",
    "# FlashrankRerank.update_forward_refs(Ranker=RankerModel)\n",
    "\n",
    "# Now, you can use the FlashrankRerank with the RankerModel\n",
    "compressor = FlashrankRerank(model_name=\"ms-marco-MultiBERT-L-12\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAGModel:\n",
    "    def __init__(\n",
    "        self, docs, dataset, k, vector_store_type, reranking=False, seed=None\n",
    "    ):\n",
    "        load_dotenv()\n",
    "        self.docs = docs\n",
    "        self.dataset = dataset\n",
    "        self.k = k\n",
    "        self.vector_store_type = vector_store_type\n",
    "        self.reranking = reranking\n",
    "        self.huggingface_token = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")\n",
    "        self.groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "        self.vector_store = None\n",
    "        self.embeddings = None\n",
    "        self.retriever = None\n",
    "        self.retrievalQA = None\n",
    "        self.prompt_template = None\n",
    "        self.seed = seed\n",
    "\n",
    "        if seed is not None:\n",
    "            self.set_seed(seed)\n",
    "\n",
    "    def set_seed(self, seed):\n",
    "        logger.info(f\"Setting random seed: {seed}.\")\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        # Set seed for other libraries if necessary\n",
    "        # Example for TensorFlow: tf.random.set_seed(seed)\n",
    "        # Example for PyTorch: torch.manual_seed(seed)\n",
    "        # If using CUDA: torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    def setup_embeddings(self):\n",
    "        logger.info(\"Setting up embeddings.\")\n",
    "        self.embeddings = OpenAIEmbeddings()\n",
    "\n",
    "    def setup_vector_store(self):\n",
    "        logger.info(f\"Setting up vector store: {self.vector_store_type}.\")\n",
    "        if self.vector_store_type == \"FAISS\":\n",
    "            self.vector_store = FAISS.from_documents(self.docs, self.embeddings)\n",
    "        elif self.vector_store_type == \"Chroma\":\n",
    "            self.vector_store = Chroma.from_documents(self.docs, self.embeddings)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported vector store type: {self.vector_store_type}\")\n",
    "\n",
    "    def setup_prompt_template(self):\n",
    "        logger.info(\"Setting up prompt template.\")\n",
    "        self.prompt_template = PromptTemplate(\n",
    "            input_variables=[\"context\", \"question\"],\n",
    "            template=\"\"\" Using the information contained in the context, give a comprehensive answer to the question.\n",
    "            Respond only to the question asked, response should be concise and relevant to the question.\n",
    "            If the answer cannot be deduced from the context, use your own knowledge.\n",
    "            Given the following context: {context}, answer the question: {question}\"\"\",\n",
    "        )\n",
    "\n",
    "    def setup_retriever(self):\n",
    "        logger.info(\"Setting up retriever.\")\n",
    "        self.retriever = self.vector_store.as_retriever(\n",
    "            search_type=\"similarity\", search_kwargs={\"k\": self.k}\n",
    "        )\n",
    "\n",
    "        if self.reranking_method == \"flash\":\n",
    "            self.retriever = self.rerank_results()\n",
    "\n",
    "    def setup_llm(self, name):\n",
    "        logger.info(f\"Setting up LLM: {name}.\")\n",
    "        self.llm = ChatGroq(groq_api_key=self.groq_api_key, model_name=name)\n",
    "\n",
    "    def refine_query(self, original_query):\n",
    "        logger.info(\"Refining query.\")\n",
    "        refined_query = self.llm.invoke(\n",
    "            f\"Rewrite the query for better retrieval: {original_query}\"\n",
    "        )\n",
    "        return refined_query\n",
    "\n",
    "    # def rerank_results_colbert(self, query, source_docs):\n",
    "        \n",
    "    #     docs = self.retriever.invoke(query)\n",
    "    #     docs=[doc.page_content for doc in docs]\n",
    "    #     # Integrate the reranker\n",
    "    #     logger.info(\"Reranking results.\")\n",
    "    #     reranked_results = RERANKER.rerank(query, docs, self.k)\n",
    "    #     return reranked_results[: self.k]\n",
    "\n",
    "    def rerank_results(self,):\n",
    "        compression_retriever = ContextualCompressionRetriever(\n",
    "            base_compressor=compressor, base_retriever=self.retriever\n",
    "        )\n",
    "        return compression_retriever\n",
    "\n",
    "    def setup_retrieverQA(self):\n",
    "        logger.info(\"Setting up RetrievalQA chain.\")\n",
    "        self.retrievalQA = RetrievalQA.from_chain_type(\n",
    "            llm=self.llm,\n",
    "            chain_type=\"stuff\",\n",
    "            retriever=self.retriever,\n",
    "            return_source_documents=True,\n",
    "            chain_type_kwargs={\"prompt\": self.prompt_template},\n",
    "        )\n",
    "\n",
    "    def generate_rag_answer(self, query):\n",
    "        logger.info(\"Refining the query {query}.\")\n",
    "        query = self.refine_query(query)\n",
    "        logger.info(f\"Refined query: {query}.\")\n",
    "        \n",
    "        logger.info(f\"Generating RAG answer for query: {query}.\")\n",
    "        result = self.retrievalQA.invoke({\"query\": query})\n",
    "        answer = result[\"result\"]\n",
    "        source_documents = result[\"source_documents\"]\n",
    "        return answer, source_documents\n",
    "\n",
    "    def create_ragas_dataset(self, column_name=\"ground_truth\"):\n",
    "        logger.info(\"Creating RAGAS dataset.\")\n",
    "        rag_dataset = []\n",
    "        for index, row in tqdm(\n",
    "            self.dataset.iterrows(),\n",
    "            total=self.dataset.shape[0],\n",
    "            desc=\"Processing questions\",\n",
    "        ):\n",
    "            answer, source_docs = self.generate_rag_answer(row[\"question\"])\n",
    "\n",
    "            rag_dataset.append(\n",
    "                {\n",
    "                    \"question\": row[\"question\"],\n",
    "                    \"answer\": answer,\n",
    "                    \"contexts\": [context.page_content for context in source_docs],\n",
    "                    \"ground_truths\": [row[column_name]],\n",
    "                }\n",
    "            )\n",
    "        rag_df = pd.DataFrame(rag_dataset)\n",
    "        rag_eval_dataset = Dataset.from_pandas(rag_df)\n",
    "        return rag_eval_dataset\n",
    "\n",
    "    def evaluate(self, ragas_dataset):\n",
    "        logger.info(\"Evaluating RAGAS dataset.\")\n",
    "        result = evaluate(\n",
    "            ragas_dataset,\n",
    "            metrics=[\n",
    "                context_precision,\n",
    "                faithfulness,\n",
    "                answer_relevancy,\n",
    "                context_recall,\n",
    "                context_relevancy,\n",
    "                answer_correctness,\n",
    "                answer_similarity,\n",
    "            ],\n",
    "        )\n",
    "        logger.info(\"Evaluation complete.\")\n",
    "        return result\n",
    "\n",
    "    def test_set_generation(self):\n",
    "        logger.info(\"Generating test set.\")\n",
    "        generator_llm = ChatOpenAI(model=\"gpt-3.5-turbo-16k\")\n",
    "        critic_llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "        embeddings = OpenAIEmbeddings()\n",
    "        generator = TestsetGenerator.from_langchain(\n",
    "            generator_llm, critic_llm, embeddings\n",
    "        )\n",
    "        distributions = {simple: 0.5, multi_context: 0.4, reasoning: 0.1}\n",
    "        testset = generator.generate_with_langchain_docs(self.docs, 10, distributions)\n",
    "        logger.info(\"Test set generation complete.\")\n",
    "        return pd.DataFrame(testset.to_pandas())\n",
    "\n",
    "    def save_results(self, results, filepath):\n",
    "        logger.info(f\"Saving results to {filepath}.\")\n",
    "        with open(filepath, \"w\") as file:\n",
    "            json.dump(results, file, indent=4)\n",
    "\n",
    "    def get_model_params(self):\n",
    "        params = {\n",
    "            \"k\": self.k,\n",
    "            \"vector_store_type\": self.vector_store_type,\n",
    "            \"retrieval_method\": self.retrieval_method,\n",
    "            \"seed\": self.seed,\n",
    "            \"huggingface_token\": self.huggingface_token,\n",
    "            \"groq_api_key\": self.groq_api_key,\n",
    "        }\n",
    "        return params\n",
    "\n",
    "\n",
    "# Main function for setup and testing\n",
    "logger.info(\"Starting RAG model setup.\")\n",
    "pickle_file = \"/Users/hadiibrahim/Dev/prima-power-hmi-assistant/data/docs.pkl\"\n",
    "with open(pickle_file, \"rb\") as file:\n",
    "    docs = pickle.load(file)\n",
    "dataset = pd.read_csv(\n",
    "    \"/Users/hadiibrahim/Dev/prima-power-hmi-assistant/data/testset.csv\"\n",
    ")\n",
    "model = RAGModel(\n",
    "    docs,\n",
    "    dataset,\n",
    "    k=3,\n",
    "    vector_store_type=\"FAISS\",\n",
    "    reranking=False,\n",
    "    seed=42,\n",
    ")\n",
    "model.setup_embeddings()\n",
    "model.setup_vector_store()\n",
    "model.setup_prompt_template()\n",
    "model.setup_retriever()\n",
    "model.setup_llm(\"llama3-70b-8192\")\n",
    "model.setup_retrieverQA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ragas_dataset = model.create_ragas_dataset()\n",
    "evaluation_result = model.evaluate(ragas_dataset)\n",
    "logger.info(\"RAG Model setup and evaluation complete.\")\n",
    "print(evaluation_result)\n",
    "\n",
    "evaluation_result_with_params = {\n",
    "    \"evaluation_result\": evaluation_result,\n",
    "    \"model_params\": model.get_model_params(),\n",
    "}\n",
    "model.save_results(evaluation_result_with_params, \"evaluation_results.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-mainenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
